{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "raising-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hearing-weight",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'paraguay_internas_nacionales_2022/in/Datos_v9/mesas.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m extension \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.xlsx\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      3\u001b[0m juego_datos \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mparaguay_internas_nacionales_2022\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m df_mesas \u001b[39m=\u001b[39m pandas\u001b[39m.\u001b[39;49mread_excel(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mjuego_datos\u001b[39m}\u001b[39;49;00m\u001b[39m/in/Datos_\u001b[39;49m\u001b[39m{\u001b[39;49;00mversion\u001b[39m}\u001b[39;49;00m\u001b[39m/mesas\u001b[39;49m\u001b[39m{\u001b[39;49;00mextension\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m, dtype\u001b[39m=\u001b[39;49m\u001b[39mstr\u001b[39;49m, engine\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mopenpyxl\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/excel/_base.py:482\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    481\u001b[0m     should_close \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 482\u001b[0m     io \u001b[39m=\u001b[39m ExcelFile(io, storage_options\u001b[39m=\u001b[39;49mstorage_options, engine\u001b[39m=\u001b[39;49mengine)\n\u001b[1;32m    483\u001b[0m \u001b[39melif\u001b[39;00m engine \u001b[39mand\u001b[39;00m engine \u001b[39m!=\u001b[39m io\u001b[39m.\u001b[39mengine:\n\u001b[1;32m    484\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    485\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEngine should not be specified when passing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    486\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    487\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/excel/_base.py:1695\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1692\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine \u001b[39m=\u001b[39m engine\n\u001b[1;32m   1693\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstorage_options \u001b[39m=\u001b[39m storage_options\n\u001b[0;32m-> 1695\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engines[engine](\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_io, storage_options\u001b[39m=\u001b[39;49mstorage_options)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/excel/_openpyxl.py:557\u001b[0m, in \u001b[0;36mOpenpyxlReader.__init__\u001b[0;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \u001b[39mReader using openpyxl engine.\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[39m{storage_options}\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    556\u001b[0m import_optional_dependency(\u001b[39m\"\u001b[39m\u001b[39mopenpyxl\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 557\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(filepath_or_buffer, storage_options\u001b[39m=\u001b[39;49mstorage_options)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/excel/_base.py:535\u001b[0m, in \u001b[0;36mBaseExcelReader.__init__\u001b[0;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m IOHandles(\n\u001b[1;32m    532\u001b[0m     handle\u001b[39m=\u001b[39mfilepath_or_buffer, compression\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mmethod\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mNone\u001b[39;00m}\n\u001b[1;32m    533\u001b[0m )\n\u001b[1;32m    534\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath_or_buffer, (ExcelFile, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workbook_class)):\n\u001b[0;32m--> 535\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m    536\u001b[0m         filepath_or_buffer, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m, storage_options\u001b[39m=\u001b[39;49mstorage_options, is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m    537\u001b[0m     )\n\u001b[1;32m    539\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workbook_class):\n\u001b[1;32m    540\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbook \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[1;32m    866\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[1;32m    868\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'paraguay_internas_nacionales_2022/in/Datos_v9/mesas.xlsx'"
     ]
    }
   ],
   "source": [
    "version = 'v9'\n",
    "extension = '.xlsx'\n",
    "juego_datos = 'paraguay_internas_nacionales_2022'\n",
    "df_mesas = pandas.read_excel(f'{juego_datos}/in/Datos_{version}/mesas{extension}', dtype=str, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-yesterday",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mesas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-herald",
   "metadata": {},
   "source": [
    "# Arranco con lo facilito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-surgeon",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paises = pandas.DataFrame(columns=['id_pais','descripcion'])\n",
    "\n",
    "for index,row in df_mesas.iterrows():\n",
    "    df_paises.at[index,'id_pais'] = row['codeleccion']\n",
    "    df_paises.at[index,'descripcion'] = row['deseleccion']\n",
    "    \n",
    "    \n",
    "    #df_paises['id_pais'] = row['codeleccio']\n",
    "    #print(row['codeleccio'])\n",
    "df_paises = df_paises.drop_duplicates(subset =\"id_pais\")\n",
    "df_paises.to_csv (f'{juego_datos}/out/{version}/paises.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-bernard",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-brisbane",
   "metadata": {},
   "source": [
    "# voy a hacer todo secuencial porque hoy estoy poco creativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-president",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distritos = pandas.DataFrame(columns=['id_distrito','id_pais','descripcion'])\n",
    "\n",
    "#voy por distritos el path de los distritos es pais.distrito - que viene dado por eleccion.departamento\n",
    "for index,row in df_mesas.iterrows():\n",
    "    path_id = f\"{row['codeleccion']}.{row['coddepartamento']}\"\n",
    "    id_pais = row['codeleccion']\n",
    "    #print(path_id)\n",
    "    df_distritos.at[index,'id_pais'] = row['codeleccion']\n",
    "    df_distritos.at[index,'id_distrito'] = path_id\n",
    "    df_distritos.at[index,'descripcion'] = row['desdepartamento'].replace(\"'\", \"’\").replace(\"\\n\", \" \")\n",
    "    \n",
    "df_distritos = df_distritos.drop_duplicates(subset =\"id_distrito\")\n",
    "df_distritos.to_csv (f'{juego_datos}/out/{version}/distritos.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-austria",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distritos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-commodity",
   "metadata": {},
   "source": [
    "# Voy por departamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-lucas",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_departamentos = pandas.DataFrame(columns=['id_departamento','id_distrito','descripcion'])\n",
    "\n",
    "for index,row in df_mesas.iterrows():\n",
    "    path_id = f\"{row['codeleccion']}.{row['coddepartamento']}.{row['coddistrito']}\"\n",
    "    #id_departamento = row['coddistrit']\n",
    "    df_departamentos.at[index,'id_departamento'] = path_id\n",
    "    df_departamentos.at[index,'id_distrito'] = f\"{row['codeleccion']}.{row['coddepartamento']}\"\n",
    "    df_departamentos.at[index,'descripcion'] = row['desdistrito'].replace(\"'\", \"’\").replace(\"\\n\", \" \")\n",
    "\n",
    "    \n",
    "    \n",
    "df_departamentos = df_departamentos.drop_duplicates(subset =\"id_departamento\")\n",
    "df_departamentos.to_csv (f'{juego_datos}/out/{version}/departamentos.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-polyester",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_departamentos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-bronze",
   "metadata": {},
   "source": [
    "# Localidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_localidades = pandas.DataFrame(columns=['id_localidad','id_departamento','descripcion'])\n",
    "\n",
    "for index,row in df_mesas.iterrows():\n",
    "    path_id = f\"{row['codeleccion']}.{row['coddepartamento']}.{row['coddistrito']}.{row['codzona']}\"\n",
    "    df_localidades.at[index,'id_localidad'] = path_id\n",
    "    df_localidades.at[index,'id_departamento'] = f\"{row['codeleccion']}.{row['coddepartamento']}.{row['coddistrito']}\"\n",
    "    df_localidades.at[index,'descripcion'] = row['deszona'].replace(\"'\", \"’\").replace(\"\\n\", \" \")\n",
    "    \n",
    "\n",
    "\n",
    "df_localidades = df_localidades.drop_duplicates(subset =\"id_localidad\")\n",
    "df_localidades.to_csv (f'{juego_datos}/out/{version}/localidades.csv', index = False, header=True)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_localidades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-ethernet",
   "metadata": {},
   "source": [
    "# Establecimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-provision",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_establecimientos = pandas.DataFrame(columns=['id_establecimiento','id_localidad','descripcion','nro_escuela','latitud','longitud','domicilio','telefono','nombre_directivo','ciudadanos_habilitados'])\n",
    "\n",
    "for index,row in df_mesas.iterrows():\n",
    "    path_id = f\"{row['codeleccion']}.{row['coddepartamento']}.{row['coddistrito']}.{row['codzona']}.{row['codlocal']}\"\n",
    "    df_establecimientos.at[index,'id_establecimiento'] = path_id\n",
    "    df_establecimientos.at[index,'nro_escuela'] = row['codlocal']\n",
    "    df_establecimientos.at[index,'ciudadanos_habilitados'] = 0 #row['electores']\n",
    "    df_establecimientos.at[index,'id_localidad'] = f\"{row['codeleccion']}.{row['coddepartamento']}.{row['coddistrito']}.{row['codzona']}\"\n",
    "    df_establecimientos.at[index,'descripcion'] = row['deslocal'].replace(\"'\", \"’\").replace(\"\\n\", \" \")\n",
    "    \n",
    "df_establecimientos = df_establecimientos.drop_duplicates(subset =\"id_establecimiento\")\n",
    "print(len(df_establecimientos['id_establecimiento'].to_list()))\n",
    "print(len(set(df_establecimientos['id_establecimiento'].to_list())))\n",
    "df_establecimientos.to_csv (f'{juego_datos}/out/{version}/establecimientos.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-humanity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_establecimientos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-directory",
   "metadata": {},
   "source": [
    "# Mesas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mesas_output = pandas.DataFrame(columns=['id_mesa','id_establecimiento','nro_mesa','sexo','tipo','extranjera','ciudadanos_habilitados'])\n",
    "\n",
    "id_mesa = 0\n",
    "\n",
    "for index,row in df_mesas.iterrows():\n",
    "    path_id = f\"{row['codeleccion']}.{row['coddepartamento']}.{row['coddistrito']}.{row['codzona']}.{row['codlocal']}.{row['mesa']}\"\n",
    "    df_mesas_output.at[index,'nro_mesa'] = path_id\n",
    "    df_mesas_output.at[index,'sexo'] = 'X'\n",
    "    df_mesas_output.at[index,'tipo'] = 'Electronica'\n",
    "    df_mesas_output.at[index,'extranjera'] = 'SI' if row['tipo'] == 'MAYORES' else 'NO'\n",
    "    df_mesas_output.at[index,'ciudadanos_habilitados'] = 500\n",
    "    df_mesas_output.at[index,'id_mesa'] = id_mesa\n",
    "    df_mesas_output.at[index,'id_establecimiento'] =  f\"{row['codeleccion']}.{row['coddepartamento']}.{row['coddistrito']}.{row['codzona']}.{row['codlocal']}\"\n",
    "    id_mesa += 1\n",
    "    \n",
    "df_mesas_output = df_mesas_output.drop_duplicates(subset =\"nro_mesa\")\n",
    "df_mesas_output.to_csv(f'{juego_datos}/out/{version}/mesas.csv', index = False, header=True)\n",
    "df_mesas_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-mount",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "en_apostrofe = re.compile(\"'([a-zA-Z\\.áéíóúñü]+)'\", re.IGNORECASE | re.UNICODE)\n",
    "en_apostrofe_d = re.compile(\"''([a-z\\.\\sA-Záéíóúñü]+)''\", re.IGNORECASE | re.UNICODE)\n",
    "en_doble_comilla = re.compile('\"([a-z\\.\\s\\'1-9A-Záéíóúñü]+)\"', re.IGNORECASE | re.UNICODE)\n",
    "\n",
    "en_comilla = re.compile('’([a-z\\.A-Záéíóúñü]+)’', re.IGNORECASE | re.UNICODE)\n",
    "en_comilla_ds = re.compile('’’([a-z\\.\\sA-Záéíóúñü]+)’’', re.IGNORECASE | re.UNICODE)\n",
    "\n",
    "en_comilla_doble = re.compile('″([a-z\\.\\sA-Záéíóúñü]+)″', re.IGNORECASE | re.UNICODE)\n",
    "en_comilla_dd = re.compile('″″([a-z\\.\\sA-Záéíóúñü]+)″″', re.IGNORECASE | re.UNICODE)\n",
    "\n",
    "\n",
    "en_comilla_raras = re.compile('´([a-z\\.A-Záéíóúñü]+)´', re.IGNORECASE | re.UNICODE)\n",
    "en_comilla_ds_raras = re.compile('´´([a-z\\.\\sA-Záéíóúñü]+)´´', re.IGNORECASE | re.UNICODE)\n",
    "en_comilla_ds_raras_ext1 = re.compile('´´´([a-z\\.\\sA-Záéíóúñü]+)´´', re.IGNORECASE | re.UNICODE)\n",
    "en_comilla_ds_raras_inv = re.compile('``([a-z\\.\\sA-Záéíóúñü]+)``', re.IGNORECASE | re.UNICODE)\n",
    "\n",
    "busqueda_verbose = False\n",
    "\n",
    "def buscar_comillas_comunes(texto):\n",
    "    \n",
    "    encom = en_apostrofe_d.search(texto)\n",
    "    if encom:\n",
    "        a_reemplazar = \"''\"+encom.group(1)+\"''\"\n",
    "        texto = texto.replace(a_reemplazar, '“'+encom.group(1)+'”')\n",
    "        if busqueda_verbose:\n",
    "            print(a_reemplazar, texto)\n",
    "        \n",
    "    encom = en_apostrofe.search(texto)\n",
    "    if encom:        \n",
    "        a_reemplazar = \"'\"+encom.group(1)+\"'\"\n",
    "        texto = texto.replace(a_reemplazar, '“'+encom.group(1)+'”')\n",
    "        if busqueda_verbose:\n",
    "            print(a_reemplazar, texto)\n",
    "        \n",
    "    encom = en_doble_comilla.search(texto)\n",
    "    if encom:\n",
    "        a_reemplazar = '\"'+encom.group(1)+'\"'\n",
    "        texto = texto.replace(a_reemplazar, '“'+encom.group(1)+'”')\n",
    "        if busqueda_verbose:\n",
    "            print(a_reemplazar, texto)\n",
    "        \n",
    "    return texto\n",
    "\n",
    "def buscar_comillas(texto):\n",
    "    encom = en_comilla_ds.search(texto)\n",
    "    if encom:        \n",
    "        a_reemplazar = '’’'+encom.group(1)+'’’'\n",
    "        texto = texto.replace(a_reemplazar, '“'+encom.group(1)+'”')\n",
    "        if busqueda_verbose:\n",
    "            print(a_reemplazar, texto)\n",
    "\n",
    "    encom = en_comilla.search(texto)\n",
    "    if encom:\n",
    "        a_reemplazar = '’'+encom.group(1)+'’'\n",
    "        texto = texto.replace(a_reemplazar, '“'+encom.group(1)+'”')\n",
    "        if busqueda_verbose:\n",
    "            print(a_reemplazar, texto)\n",
    "    return texto\n",
    "\n",
    "def buscar_comillas_raras(texto):\n",
    "    \n",
    "    encom = en_comilla_ds_raras_ext1.search(texto)\n",
    "    if encom:        \n",
    "        a_reemplazar = '´´´'+encom.group(1)+'´´'\n",
    "        texto = texto.replace(a_reemplazar, '“'+encom.group(1)+'”')\n",
    "        if busqueda_verbose:\n",
    "            print(a_reemplazar, texto)\n",
    "        \n",
    "    encom = en_comilla_ds_raras.search(texto)\n",
    "    if encom:        \n",
    "        a_reemplazar = '´´'+encom.group(1)+'´´'\n",
    "        texto = texto.replace(a_reemplazar, '“'+encom.group(1)+'”')\n",
    "        if busqueda_verbose:\n",
    "            print(a_reemplazar, texto)\n",
    "    \n",
    "    encom = en_comilla_ds_raras_inv.search(texto)\n",
    "    if encom:        \n",
    "        a_reemplazar = '``'+encom.group(1)+'``'\n",
    "        texto = texto.replace(a_reemplazar, '“'+encom.group(1)+'”')\n",
    "        if busqueda_verbose:\n",
    "            print(a_reemplazar, texto)\n",
    "\n",
    "    encom = en_comilla_raras.search(texto)\n",
    "    if encom:\n",
    "        a_reemplazar = '´'+encom.group(1)+'´'\n",
    "        texto = texto.replace(a_reemplazar, '“'+encom.group(1)+'”')\n",
    "        if busqueda_verbose:\n",
    "            print(a_reemplazar, texto)\n",
    "    return texto\n",
    "\n",
    "def buscar_comillas_dobles(texto):\n",
    "    encom = en_comilla_dd.search(texto)\n",
    "    if encom:        \n",
    "        a_reemplazar = '″″'+encom.group(1)+'″″'\n",
    "        texto = texto.replace(a_reemplazar, '“'+encom.group(1)+'”')\n",
    "        if busqueda_verbose:\n",
    "            print(a_reemplazar, texto)\n",
    "\n",
    "    encom = en_comilla_doble.search(texto)\n",
    "    if encom:\n",
    "        a_reemplazar = '″'+encom.group(1)+'″'\n",
    "        texto = texto.replace(a_reemplazar, '“'+encom.group(1)+'”')\n",
    "        if busqueda_verbose:\n",
    "            print(a_reemplazar, texto)\n",
    "    return texto\n",
    "\n",
    "\n",
    "def quitar_comillas(original):\n",
    "    texto = buscar_comillas_comunes(original)\n",
    "    texto = buscar_comillas(texto)\n",
    "    texto = buscar_comillas_raras(texto)\n",
    "    texto = buscar_comillas_dobles(texto)\n",
    "    # Si queda algun apóstrofe o comillas dobles dando vuelta lo reemplazamos\n",
    "    texto = texto.replace(\"'\",\"’\")\n",
    "    texto = texto.replace('\"',\"’\")\n",
    "    if original != texto and busqueda_verbose:\n",
    "        print(original,'---' , texto)\n",
    "    return texto\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-elephant",
   "metadata": {},
   "source": [
    "# Listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-element",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "df_listas = pandas.read_excel(f'{juego_datos}/in/Datos_{version}/listas{extension}', dtype=str).fillna('')\n",
    "\n",
    "# Paso los encabezados a minusculas \n",
    "df_listas.columns = [c.lower() for c in df_listas.columns]\n",
    "\n",
    "df_listas_output = pandas.DataFrame(columns=['id_lista','id_partido','descripcion','texto_asistida','descripcion_corta','nro_lista','color','color_tipografia','color_api_resultados','nro_orden'])\n",
    "\n",
    "listas = []\n",
    "for index,row in df_listas.iterrows():\n",
    "    cod_lista = row['codlista'].strip()\n",
    "    if cod_lista not in df_listas_output['id_lista'].to_list():\n",
    "        data = ''\n",
    "        if 'presidente' in row and row['presidente'].strip() != '':\n",
    "            data = json.dumps({\n",
    "                'presidente': quitar_comillas(row['presidente']),\n",
    "                'vice_1': quitar_comillas(row['vice_1']),\n",
    "                'vice_2': quitar_comillas(row['vice_2']),\n",
    "            })\n",
    "        \n",
    "        # Agrega el color si fueron establecidos lo 3 colores R,G y B\n",
    "        color = None\n",
    "        color_tipografia = ''\n",
    "        if 'color_r' in row and 'color_g' in row and 'color_b' in row:\n",
    "            try:\n",
    "                color = '#%02x%02x%02x' % (int(row['color_r']), int(row['color_g']), int(row['color_b']))\n",
    "                \n",
    "                # Color de la tipografía en base al fondo, para que haya contraste\n",
    "                thresh = round(((int(row['color_r']) * 299) + (int(row['color_g']) * 587) + (int(row['color_b']) * 114)) /1000)                \n",
    "                if thresh <= 125:\n",
    "                    color_tipografia = '#ffffff'\n",
    "                else:\n",
    "                    color_tipografia = '#000000'\n",
    "                    \n",
    "            except:\n",
    "                #print('Alguno de los colores no fue establecido para la lista',row['codlista'])\n",
    "                color_tipografia = '#000000'\n",
    "                pass\n",
    "        else:\n",
    "            color_tipografia = '#000000'\n",
    "            \n",
    "        nueva_descripcion = quitar_comillas(row['descripcion'])\n",
    "        if nueva_descripcion == '':\n",
    "            print('La descripcion de la lista',row['codlista'],'esta vacía.')\n",
    "        nueva_descripcion_corta = quitar_comillas(row['descripcion_corta'])\n",
    "        if nueva_descripcion_corta == '':\n",
    "            print('La descripcion corta de la lista',row['codlista'],'esta vacía.')\n",
    "        new_row = {\n",
    "            'id_lista': cod_lista,\n",
    "            'id_partido': '',\n",
    "            'descripcion': nueva_descripcion,\n",
    "            'texto_asistida': row['numlista'] +' - '+ nueva_descripcion,\n",
    "            'descripcion_corta': nueva_descripcion_corta,\n",
    "            'nro_lista': row['numlista'],\n",
    "            'color': color,\n",
    "            'color_tipografia': color_tipografia,\n",
    "            'color_api_resultados': '',\n",
    "            'nro_orden': row['nro_orden'],\n",
    "            'data': data\n",
    "        }\n",
    "        \n",
    "        listas.append(new_row)\n",
    "        \n",
    "df_listas_output = pandas.DataFrame.from_dict(listas)\n",
    "df_listas_output.to_csv (f'{juego_datos}/out/{version}/listas.csv', index = False, header=True)\n",
    "df_listas_output[df_listas_output.duplicated('id_lista', keep=False)].to_csv('/tmp/errores_listas_duplicadas.csv')\n",
    "assert len(df_listas_output[df_listas_output.duplicated('id_lista', keep=False)]) == 0, 'Existen listas duplicadas, consultar /tmp/errores_listas_duplicadas.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-enforcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listas_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-chile",
   "metadata": {},
   "source": [
    "# y por ultimo candidatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-vancouver",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ubicacion(nivel, nivel_para, dep, dis, zona, elec):\n",
    "    if nivel == nivel_para:\n",
    "        if nivel == 'NACIONAL':\n",
    "            return str(elec)\n",
    "        elif nivel == 'DEPARTAMENTO':\n",
    "            return '.'.join([str(elec), dep])\n",
    "        elif nivel == 'DISTRITO':\n",
    "            return '.'.join([str(elec), dep, dis])\n",
    "        elif nivel == 'ZONA':\n",
    "            return '.'.join([str(elec), dep, dis, zona])\n",
    "    return ''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-shareware",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_candidaturas = pandas.read_csv(f'in/Datos_{version}/candidaturas.csv', delimiter=';', dtype=str).fillna(' ')\n",
    "df_candidaturas = pandas.read_excel(f'{juego_datos}/in/Datos_{version}/candidaturas{extension}', dtype=str).fillna('')\n",
    "candidaturas = {}\n",
    "for index,row in df_candidaturas.iterrows():\n",
    "    candidaturas[row['codcandidatura']] = {\n",
    "        'descripcion': row['descripcion'],\n",
    "        'descripcion_corta': row['descripcion_corta'],\n",
    "        'nivel': row['nivel'],\n",
    "        'nro_orden': row['nro_orden'],\n",
    "        'tipo': row['tipo']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidatos = pandas.read_excel(f'{juego_datos}/in/Datos_{version}/candidatos{extension}', dtype=str).fillna('')\n",
    "\n",
    "# Paso los encabezados a minusculas \n",
    "df_candidatos.columns = [c.lower() for c in df_candidatos.columns]\n",
    "\n",
    "df_candidatos_output = pandas.DataFrame(columns=['id_candidato','id_lista','id_cargo','id_pais',\n",
    "                                                 'id_distrito','id_departamento','id_localidad',\n",
    "                                                 'nombre','nro_orden','sexo','dni','texto_asistida','titular'])\n",
    "\n",
    "log_errores_candidatos = open('/tmp/errores_candidatos.txt', mode='w', encoding='utf-8')\n",
    "\n",
    "nros_orden_candidatos = {}\n",
    "\n",
    "claves_existente = []\n",
    "candidatos = []\n",
    "\n",
    "lista_id_pais = df_paises['id_pais'].to_list()\n",
    "lista_id_distrito = df_distritos['id_distrito'].to_list()\n",
    "lista_id_departamento = df_departamentos['id_departamento'].to_list()\n",
    "lista_id_localidad = df_localidades['id_localidad'].to_list()\n",
    "\n",
    "for index,row in df_candidatos.iterrows():\n",
    "    nivel = candidaturas[row['codcandidatura']]['nivel']\n",
    "    id_pais = get_ubicacion(nivel, 'NACIONAL', row['coddepartamento'], row['coddistrito'], row['codzona'], row['codeleccion'])\n",
    "    id_distrito = get_ubicacion(nivel, 'DEPARTAMENTO', row['coddepartamento'], row['coddistrito'], row['codzona'], row['codeleccion'])\n",
    "    id_departamento = get_ubicacion(nivel, 'DISTRITO', row['coddepartamento'], row['coddistrito'], row['codzona'], row['codeleccion'])\n",
    "    id_localidad = get_ubicacion(nivel, 'ZONA', row['coddepartamento'], row['coddistrito'], row['codzona'], row['codeleccion'])\n",
    "    \n",
    "    if id_pais != '' and id_pais not in lista_id_pais:\n",
    "        msj = 'El id candidato '+ row['idcandidato']+' se encuentra asociado a una ELECCION '+id_pais+' que no existe en el archivo de mesas.'\n",
    "        print(msj)\n",
    "        log_errores_candidatos.write(msj+'\\n')\n",
    "        continue\n",
    "    \n",
    "    if id_distrito != '' and id_distrito not in lista_id_distrito:\n",
    "        msj = 'El id candidato '+row['idcandidato']+' se encuentra asociado a un DEPARTAMENTO '+id_distrito+' que no existe en el archivo de mesas.'\n",
    "        print(msj)\n",
    "        log_errores_candidatos.write(msj+'\\n')\n",
    "        continue\n",
    "    \n",
    "    if id_departamento != '' and id_departamento not in lista_id_departamento:\n",
    "        msj = 'El id candidato '+ row['idcandidato']+ ' se encuentra asociado a un DISTRITO '+ id_departamento+ ' que no existe en el archivo de mesas.'\n",
    "        print(msj)\n",
    "        log_errores_candidatos.write(msj+'\\n')\n",
    "        continue\n",
    "    \n",
    "    if id_localidad != '' and id_localidad not in lista_id_localidad:\n",
    "        msj = 'El id candidato '+ row['idcandidato']+ ' se encuentra asociado a una ZONA '+ id_localidad+ ' que no existe en el archivo de mesas.'\n",
    "        print(msj)\n",
    "        log_errores_candidatos.write(msj+'\\n')\n",
    "        continue\n",
    "    \n",
    "    id_lista = row['codlista']\n",
    "    candidatura = candidaturas[row['codcandidatura']]['descripcion']\n",
    "    id_cargo = candidaturas[row['codcandidatura']]['descripcion_corta']\n",
    "    clave_lista = (id_pais, id_distrito, id_departamento, id_localidad, id_lista, id_cargo)\n",
    "        \n",
    "    if row['orden'] == '0':\n",
    "        print('El id candidato', row['idcandidato'], 'tiene orden 0')\n",
    "        \n",
    "    nro_orden = row['orden']\n",
    "    \n",
    "    clave_preferente = (id_pais, id_distrito, id_departamento, id_localidad, id_lista, id_cargo, nro_orden)\n",
    "    if clave_preferente in claves_existente:\n",
    "        ubicacion = None\n",
    "        for c in clave_preferente[:4]:\n",
    "            if c != '':\n",
    "                ubicacion = c\n",
    "        msj = 'El candidato con id '+ row['idcandidato']+ ' pisa otro candidato para la Ubicacion '+ \\\n",
    "                    ubicacion+ ' Candidatura '+ candidatura+ ' Lista '+ id_lista+ ' Nro de orden' + nro_orden\n",
    "        print(msj)\n",
    "        log_errores_candidatos.write(msj+'\\n')\n",
    "        continue\n",
    "    else:\n",
    "        claves_existente.append(clave_preferente)\n",
    "    \n",
    "    # TODO Hay que corregir enrique tercero en asistida porque va a pisar el arreglo hecho para el juego v12\n",
    "    #exit(0)\n",
    "    nuevo_nombre = quitar_comillas(row['nombre'])\n",
    "    \n",
    "    # Capitaliza el nombre\n",
    "    #nuevo_nombre = ' '.join([x.capitalize() for x in nuevo_nombre.split(' ')])\n",
    "    #EL-7578 Candidatos con apodos en minúscula deben estar con Mayúsculas\n",
    "    nuevo_nombre = ' '.join([x.capitalize() if \"“\" not in x else x for x in nuevo_nombre.split(' ')])\n",
    "\n",
    "    \n",
    "    new_row = {\n",
    "        'id_candidato': index,\n",
    "        'id_lista': id_lista,\n",
    "        'id_cargo': id_cargo,\n",
    "        'id_pais': id_pais,\n",
    "        'id_distrito': id_distrito,\n",
    "        'id_departamento': id_departamento,\n",
    "        'id_localidad': id_localidad,\n",
    "        'nombre': nuevo_nombre,\n",
    "        'nro_orden': nro_orden,\n",
    "        #'sexo': row['sexo'],\n",
    "        'sexo': '',\n",
    "        'dni': row['idcandidato'],\n",
    "        'texto_asistida': nuevo_nombre,\n",
    "        'titular': \"SI\"\n",
    "    }        \n",
    "    candidatos.append(new_row)\n",
    "    \n",
    "    \n",
    "df_candidatos_output = pandas.DataFrame.from_dict(candidatos)\n",
    "df_candidatos_output.to_csv (f'{juego_datos}/out/{version}/candidatos.csv', index = False, header=True)\n",
    "df_candidatos_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidatos_output.groupby(['id_cargo', 'id_pais', 'id_distrito', 'id_departamento', 'id_localidad', 'id_lista']).agg(['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-bronze",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #23.2.21.459\n",
    "# #print(df_listas.columns)\n",
    "# import pandas\n",
    "# df_listas = pandas.read_excel('Votos PLRA/plra_07_candidatos_v2.xls', dtype=str).fillna(' ')\n",
    "# #Index(['idcandidat', 'codcandida', 'descandida', 'coddeparta', 'desdeparta',\n",
    "#        #'coddistrit', 'desdistrit', 'codzona', 'deszona', 'nivel', 'numlista',\n",
    "#        #'codlista', 'deslista', 'orden', 'cedula', 'nombre', 'apellido',\n",
    "#        #'tipo'],\n",
    "# #print(set(df_listas['descandida'].to_list()))\n",
    "# df_listas.query(\"coddeparta == '8' & coddistrit == '7' & numlista == '521' & nivel == 'DISTRITOS'\")\n",
    "# #df_listas.query('descandida == \"DIRECTORIO NACIONAL\" & numlista == \"505\"') 23.2.11\n",
    "\n",
    "# #df_listas = pandas.read_csv('Votos PLRA/plra_07_candidatos.csv', dtype=str).fillna(' ')\n",
    "# #El candidato ya existe ('', '', '', '23.10.0.226', '582', 'CL', '2')\n",
    "# #df_listas['descandida'].unique()\n",
    "# #df_listas['descandida'].unique()\n",
    "# #pandas.set_option('display.max_rows', 510)\n",
    "# #df_listas.query(\"orden == '0'\")\n",
    "# #['descandida'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-cream",
   "metadata": {},
   "outputs": [],
   "source": [
    "#23.2.21.459\n",
    "# import pandas\n",
    "# # pandas.set_option('display.max_rows', 510)\n",
    "# df_listas = pandas.read_excel('Votos PLRA/plra_07_candidatos_v2.xls', dtype=str).fillna(' ')\n",
    "# #Index(['idcandidat', 'codcandida', 'descandida', 'coddeparta', 'desdeparta',\n",
    "#        #'coddistrit', 'desdistrit', 'codzona', 'deszona', 'nivel', 'numlista',\n",
    "#        #'codlista', 'deslista', 'orden', 'cedula', 'nombre', 'apellido',\n",
    "#        #'tipo'],\n",
    "# df_listas.query(\"nivel == 'NACIONALES' & numlista == '575'\")\n",
    "# #df_listas.query(\"descandida == 'JUNTA MUNICIPAL' & (orden == '0' )\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-salem",
   "metadata": {},
   "source": [
    "# Cargos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-brief",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cargos_msa = pandas.DataFrame(columns=['id_cargo',\n",
    "                                          'id_cargo_descriptivo',\n",
    "                                          'descripcion',\n",
    "                                          'nro_orden',\n",
    "                                          'descripcion_corta',\n",
    "                                          'texto_asistida',\n",
    "                                          'max_selecciones',\n",
    "                                          'consulta_popular',\n",
    "                                          'cargo_ejecutivo',\n",
    "                                          'id_grupo',\n",
    "                                          'preferente',\n",
    "                                          'tachas',\n",
    "                                          'max_tachas',\n",
    "                                          'max_preferencias'])\n",
    "\n",
    "def get_des_corta(descr):\n",
    "        res = ''\n",
    "        partes = descr.split(' ')\n",
    "        for p in partes:\n",
    "            if len(p) > 2:\n",
    "                res += p[:2]+'. '\n",
    "        res = res.strip()[:20]\n",
    "        if len(res) > 20:\n",
    "            raise Exception('Exc')\n",
    "        return res\n",
    "    \n",
    "# tipo 1 es lista cerrada (lo que nosotros llamamos ejecutivo)\n",
    "id_grupo = 1\n",
    "for _,cand in candidaturas.items():\n",
    "    candidatura = cand['descripcion']\n",
    "    tipo_candidatura = cand['tipo']\n",
    "    id_cargo = cand['descripcion_corta']\n",
    "    \n",
    "    new_row = {\n",
    "        'id_cargo': id_cargo,\n",
    "        'id_cargo_descriptivo': id_cargo,\n",
    "        'descripcion': candidatura.strip(),\n",
    "          'nro_orden': id_grupo,\n",
    "          'descripcion_corta': id_cargo,\n",
    "          'texto_asistida': candidatura.strip(),\n",
    "          'max_selecciones': '1',\n",
    "          'consulta_popular': 'NO',\n",
    "          'cargo_ejecutivo': 'SI' if tipo_candidatura == '1' else 'NO',\n",
    "          'id_grupo': id_grupo,\n",
    "          'preferente': 'NO' if tipo_candidatura == '1' else 'SI',\n",
    "          'tachas': 'NO',\n",
    "          'max_tachas':'',\n",
    "          'max_preferencias': '' if tipo_candidatura == '1' else '1'\n",
    "    }\n",
    "    id_grupo += 1\n",
    "\n",
    "    df_cargos_msa = df_cargos_msa.append(new_row, ignore_index=True)\n",
    "\n",
    "df_cargos_msa.to_csv(f'{juego_datos}/out/{version}/cargos.csv', index = False, header=True)\n",
    "df_cargos_msa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-kennedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_candidatos_output['id_cargo'].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-blood",
   "metadata": {},
   "source": [
    "# ahora me encargo de magnitudes y cargos especiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-fight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agrupados.groupby(['id_cargo', 'id_pais', 'id_distrito', 'id_departamento', 'id_localidad']).idxmax('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-romania",
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitudes = []\n",
    "\n",
    "# pandas.set_option('display.max_rows', 500)\n",
    "agrupados = df_candidatos_output.groupby(['id_cargo', 'id_pais', 'id_distrito', 'id_departamento', 'id_localidad', 'id_lista']).agg(['count'])\n",
    "pre_magnitudes = agrupados.groupby(['id_cargo', 'id_pais', 'id_distrito', 'id_departamento', 'id_localidad']).first()[('id_candidato','count')]\n",
    "\n",
    "last_cargo = None\n",
    "for row, magnitud in pre_magnitudes.iteritems():\n",
    "    \n",
    "    id_pais = row[1]\n",
    "    id_distrito = row[2]\n",
    "    id_departamento = row[3]\n",
    "    id_localidad = row[4]\n",
    "    \n",
    "    if id_pais != '' and id_pais not in df_paises['id_pais'].to_list():\n",
    "        print(row['cedula'], ' se encuentra asociado a una ubicacion que no existe.')\n",
    "        continue\n",
    "    \n",
    "    if id_distrito != '' and id_distrito not in df_distritos['id_distrito'].to_list():\n",
    "        print(row['cedula'], ' se encuentra asociado a una ubicacion que no existe.')\n",
    "        continue\n",
    "    \n",
    "    if id_departamento != '' and id_departamento not in df_departamentos['id_departamento'].to_list():\n",
    "        print(row['cedula'], ' se encuentra asociado a una ubicacion que no existe.')\n",
    "        continue\n",
    "    \n",
    "    if id_localidad != '' and id_localidad not in df_localidades['id_localidad'].to_list():\n",
    "        print(row['cedula'], ' se encuentra asociado a una ubicacion que no existe.')\n",
    "        continue\n",
    "    \n",
    "    if row[0] != '' and row[0] != last_cargo:\n",
    "        last_cargo = row[0]\n",
    "        \n",
    "    new_row = {\n",
    "        'id_pais': row[1],\n",
    "        'id_distrito': row[2],\n",
    "        'id_departamento': row[3],\n",
    "        'id_localidad': row[4],\n",
    "        'id_cargo': last_cargo,\n",
    "        'titulares': magnitud,\n",
    "        'suplentes': '0',\n",
    "        'bancas': magnitud,\n",
    "        'piso': '1'\n",
    "    }\n",
    "    \n",
    "    magnitudes.append(new_row)\n",
    "df_magnitudes = pandas.DataFrame.from_dict(magnitudes)\n",
    "df_magnitudes.to_csv (f'{juego_datos}/out/{version}/magnitudes_cargos.csv', index = False, header=True)\n",
    "df_magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-heading",
   "metadata": {},
   "outputs": [],
   "source": [
    "cargos_especiales = []\n",
    "\n",
    "especiales = ['BLC','NUL', 'VAC']\n",
    "ind = 0\n",
    "\n",
    "for index,row in df_magnitudes.iterrows():\n",
    "        for especial in especiales:\n",
    "            new_row = {\n",
    "                'id_cargo': row['id_cargo'],\n",
    "                'id_especial': especial,\n",
    "                'id_pais': row.id_pais,\n",
    "                'id_distrito': row.id_distrito,\n",
    "                'id_departamento': row.id_departamento,\n",
    "                'id_localidad': row.id_localidad,\n",
    "                'habilitado': 'SI',\n",
    "                'positivo': 'SI' if especial == 'BLC' else 'NO'\n",
    "            }\n",
    "            cargos_especiales.append(new_row)\n",
    "\n",
    "df_cargos_especiales = pandas.DataFrame.from_dict(cargos_especiales)\n",
    "df_cargos_especiales = df_cargos_especiales.drop_duplicates()\n",
    "df_cargos_especiales.to_csv(f'{juego_datos}/out/{version}/cargo_especial_ubicacion.csv', index = False, header=True)\n",
    "df_cargos_especiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-harvey",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cargos_especiales['id_cargo'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-drive",
   "metadata": {},
   "source": [
    "# no_cargo_ubicacion para mesa de mayores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-celebration",
   "metadata": {},
   "outputs": [],
   "source": [
    "cargos_no_votados = ['RDJ', 'MFC', 'PVC']\n",
    "no_cargos = []\n",
    "\n",
    "for index, row in df_mesas.iterrows():\n",
    "    if row['tipo'] == 'MAYORES':\n",
    "        path_id = f\"{row['codeleccion']}.{row['coddepartamento']}.{row['coddistrito']}.{row['codzona']}.{row['codlocal']}.{row['mesa']}\"\n",
    "        for c in cargos_no_votados:\n",
    "            new_row = {\n",
    "                'id_cargo': c,\n",
    "                'id_localidad': '',\n",
    "                'id_establecimiento': '',\n",
    "                'id_mesa': '',\n",
    "                'id_ubicacion': path_id\n",
    "            }\n",
    "            no_cargos.append(new_row)\n",
    "\n",
    "df_no_cargo = pandas.DataFrame.from_dict(no_cargos)\n",
    "df_no_cargo.to_csv(f'{juego_datos}/out/{version}/no_cargo_ubicacion.csv', index = False, header=True)\n",
    "df_no_cargo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas \n",
    "# df_cargo_especial_ubic = pandas.read_csv('/home/andres/desarrollo/elecciones/msa/recursos/fuentes/datos/paraguay_municipales_actas_2021/cargo_especial_ubicacion.csv', dtype=str).fillna('')\n",
    "\n",
    "# cargados = []\n",
    "# especiales_nuevos = []\n",
    "# for i, row in df_cargo_especial_ubic.iterrows():\n",
    "#     if row['id_especial'] != 'VAC':\n",
    "#         clave = (row['id_cargo'], row['id_pais'], row['id_distrito'], row['id_departamento'], row['id_localidad'])\n",
    "#         if clave not in cargados:\n",
    "#             esp = {\n",
    "#                 'id_especial': 'VAC',\n",
    "#                 'id_cargo': row['id_cargo'],\n",
    "#                 'id_pais': row['id_pais'],\n",
    "#                 'id_distrito': row['id_distrito'],\n",
    "#                 'id_departamento': row['id_departamento'],\n",
    "#                 'id_localidad': row['id_localidad'],\n",
    "#                 'habilitado': 'SI',\n",
    "#                 'positivo': 'NO'\n",
    "#             }\n",
    "#             cargados.append(clave)\n",
    "#             especiales_nuevos.append(esp)\n",
    "\n",
    "# nuevos_df = pandas.DataFrame.from_dict(especiales_nuevos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-working",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuevos_df.to_csv('/tmp/nuevos_especiales.csv', index=False)\n",
    "#pandas.set_option('display.max_rows', 510)\n",
    "#nuevos_df.query(\"id_distrito == '22.10'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8569bf46",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-louisiana",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c34ad33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
